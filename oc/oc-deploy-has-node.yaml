apiVersion: v1
kind: Template
metadata:
  name: worker
  annotations:
    description: HDFS cluster worker deploymentconfig
    tags: networking,storage

parameters:
  - name: ID
    value: "1"
    description: Node ID
    required: true
  - name: IMAGE_HDFS
    value: "hdfs"
    description: HAS HDFS Docker image
    required: true
  - name: IMAGE_ALLUXIO
    value: "alluxio"
    description: HAS Alluxio Docker image
    required: true
  - name: IMAGE_SPARK
    value: "spark"
    description: HAS Spark Docker image
    required: true
  - name: ALLUXIO_MEMORY
    value: "4096MB"
  - name: SPARK_MEMORY
    value: "2048MB"
  - name: HDFS_MEMORY
    value: "1024MB"

objects:

  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      name: worker${ID}
      namespace: has
      labels:
        app: worker${ID}
        type: "worker"
    spec:
      strategy:
        type: Recreate
      triggers:
        - type: ConfigChange
        - type: ImageChange
          imageChangeParams:
            automatic: true
            containerNames:
              - worker
            from:
              kind: ImageStreamTag
              namespace: has
              name: 'hdfs:latest'
      replicas: 1
      test: false
      selector:
        app: worker${ID}
        deploymentconfig: worker${ID}
      template:
        metadata:
          labels:
            app: worker${ID}
            deploymentconfig: worker${ID}
            type: "worker"
        spec:
          hostname: worker${ID}
          podAntiAffinity:
            requiredDuringSchedulingIgnoreDuringExecution:
              - labelSelector:
                  matchExpressions:
                    - key: type
                      operator: In
                      values:
                        - "master"
                        - "worker"
                        - "driver"
                        - "aux" 
          volumes:
            - name: hdfs-worker-storage-${ID}
              emptyDir: {}
            - name: alluxio-worker-storage-${ID}
              emptyDir: {}
            - name: spark-worker-storage-${ID}
              emptyDir: {}
            - name: dshm
              emptyDir:
              medium: Memory
          containers:
            - name: hdfs-worker${ID}
              image: ${IMAGE_HDFS}
              resources: {}
              args:
                - datanode
                - start
                - hdfs-namenode
              volumeMounts:
                - name: hdfs-worker-storage-${ID}
                  mountPath: /data
              terminationMessagePath: /dev/termination-log
              imagePullPolicy: Always
            - name: alluxio-worker-${ID}
              image: ${IMAGE_ALLUXIO}
              resources: {}
              args:
                - slave
                - start
                - alluxio-master
              volumeMounts:
                - name: alluxio-worker-storage-${ID}
                  mountPath: /data
                - name: dshm
                  mountPath: /dev/shm
              terminationMessagePath: /dev/termination-log
              imagePullPolicy: Always
              env:
                - name: ALLUXIO_WORKER_MEMORY_SIZE
                  value: ${ALLUXIO_MEMORY}
            - name: spark-worker-${ID}
              image: ${IMAGE_SPARK}
              resources: {}
              args:
                - slave
                - start
                - spark-master
              volumeMounts:
                - name: spark-worker-storage-${ID}
                  mountPath: /data
              terminationMessagePath: /dev/termination-log
              imagePullPolicy: Always
              env:
                - name: SPARK_WORKER_MEMORY
                  value: ${SPARK_MEMORY}
          restartPolicy: Always
          terminationGracePeriodSeconds: 30
          dnsPolicy: ClusterFirst
          securityContext: {}

  - apiVersion: v1
    kind: Service
    metadata:
      name: worker${ID}
    spec:
      selector:
        app: worker${ID}
      ports:
        - name: dfs-datanode-address
          protocol: TCP
          port: 50010
          targetPort: 50010
        - name: dfs-datanode-http-address
          protocol: TCP
          port: 50075
          targetPort: 50075
        - name: dfs-datanode-ipc-address
          protocol: TCP
          port: 50020
          targetPort: 50020
        - name: alluxio-worker-metadata
          protocol: TCP
          port: 29998
          targetPort: 29998
        - name: alluxio-worker-data-transfer
          protocol: TCP
          port: 29999
          targetPort: 29999
        - name: alluxio-worker-rpc-ui
          protocol: TCP
          port: 30000
          targetPort: 30000
        - name: spark-worker-service
          protocol: TCP
          port: 35000
          targetPort: 35000
        - name: spark-worker-ui
          protocol: TCP
          port: 8081
          targetPort: 8081
        - name: spark-worker-service-bis
          protocol: TCP
          port: 6066
          targetPort: 6066
        - name: spark-blockmanager-port
          protocol: TCP
          port: 51400
          targetPort: 51400

  - apiVersion: v1
    kind: Route
    metadata:
      name: hdfs-worker${ID}
      namespace: has
    spec:
      to:
        kind: Service
        name: worker${ID}
        weight: 100
      port:
        targetPort: dfs-datanode-http-address
      wildcardPolicy: None

  - apiVersion: v1
    kind: Route
    metadata:
      name: spark-worker${ID}
      namespace: has
    spec:
      to:
        kind: Service
        name: worker${ID}
        weight: 100
      port:
        targetPort: spark-worker-ui
      wildcardPolicy: None

  - apiVersion: v1
    kind: Route
    metadata:
      name: alluxio-worker${ID}
      namespace: has
    spec:
      to:
        kind: Service
        name: worker${ID}
        weight: 100
      port:
        targetPort: alluxio-worker-rpc-ui
      wildcardPolicy: None
