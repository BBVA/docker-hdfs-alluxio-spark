apiVersion: v1
kind: Template
metadata:
  name: hdfs-datanode
  annotations:
    description: HDFS cluster
    tags: networking,storage

parameters:
  - name: ID
    value: 1
    description: Node ID
    required: true
  - name: STORAGE
    value: "1Gi"
    description: Storage assigned to the node
    required: true
  - name: IMAGE
    value: "hdfs"
    description: HAS HDFS Docker image
    required: true

objects:

  - apiVersion: v1
    kind: PersistentVolumeClaim
    metadata:
      name: hdfs-datanode-storage-${ID}
      namespace: has
    spec:
      accessModes:
      - ReadWriteMany
      resources:
        requests:
          storage: ${STORAGE}
      volumeName: hdfs-datanode-storage


  - apiVersion: v1
    kind: DeploymentConfig
    metadata:
      name: hdfs-datanode-${ID}
      namespace: has
      labels:
        app: hdfs-datanode-${ID}
    spec:
      strategy:
        type: Rolling
        rollingParams:
          updatePeriodSeconds: 1
          intervalSeconds: 1
          timeoutSeconds: 600
          maxUnavailable: 25%
          maxSurge: 25%
        resources: {}
      triggers:
        - type: ConfigChange
        - type: ImageChange
          imageChangeParams:
            automatic: true
            containerNames:
              - hdfs-datanode
            from:
              kind: ImageStreamTag
              namespace: has
              name: 'hdfs:latest'
      replicas: 1
      test: false
      selector:
        app: hdfs-datanode-${ID}
        deploymentconfig: hdfs-datanode-${ID}
      template:
        metadata:
          labels:
            app: hdfs-datanode-${ID}
            deploymentconfig: hdfs-datanode-${ID}
        spec:
          volumes:
            - name: hdfs-datanode-storage-${ID}
              persistentVolumeClaim:
                claimName: hdfs-datanode-storage
          containers:
            - name: hdfs-datanode
              image: ${IMAGE_HDFS}
              resources: {}
              args:
                - datanode
                - start
                - hdfs-namenode
              volumeMounts:
                - name: hdfs-datanode-storage-${ID}
                  mountPath: /data
              terminationMessagePath: /dev/termination-log
              imagePullPolicy: Always
            - name: alluxio-worker
              image: ${IMAGE_ALLUXIO}
              resources: {}
              args:
                - slave
                - start
                - alluxio-master
              volumeMounts:
                - name: hdfs-datanode-storage-${ID}
                  mountPath: /data
              terminationMessagePath: /dev/termination-log
              imagePullPolicy: Always
            - name: spark-worker
              image: ${IMAGE_SPARK}
              resources: {}
              args:
                - slave
                - start
                - spark-master
              volumeMounts:
                - name: hdfs-datanode-storage-${ID}
                  mountPath: /data
              terminationMessagePath: /dev/termination-log
              imagePullPolicy: Always
          restartPolicy: Always
          terminationGracePeriodSeconds: 30
          dnsPolicy: ClusterFirst
          securityContext: {}

  - apiVersion: v1
    kind: Service
    metadata:
      name: hdfs-datanode-${ID}
    spec:
      selector:
        app: hdfs-datanode-${ID}
      ports:
        - name: dfs-datanode-address
          protocol: TCP
          port: 50010
          targetPort: 50010
        - name: dfs-datanode-http-address
          protocol: TCP
          port: 50075
          targetPort: 50075
        - name: dfs-datanode-ipc-address
          protocol: TCP
          port: 50020
          targetPort: 50020
        - name: alluxio-worker-metadata
          protocol: TCP
          port: 29998
          targetPort: 29998
        - name: alluxio-worker-data-transfer
          protocol: TCP
          port: 29999
          targetPort: 29999
        - name: alluxio-worker-rpc-ui
          protocol: TCP
          port: 30000
          targetPort: 30000
        - name: spark-worker-service
          protocol: TCP
          port: 35000
          targetPort: 35000
        - name: spark-worker-ui
          protocol: TCP
          port: 8081
          targetPort: 8081
        - name: spark-worker-service
          protocol: TCP
          port: 6066
          targetPort: 6066
  - apiVersion: v1
    kind: Route
    metadata:
      name: hdfs-datanode-dashboard-${ID}
      namespace: has
      spec:
        to:
          kind: Service
          name: hdfs-datanode
          weight: 100
        port:
          targetPort: dfs-datanode-http-address
        wildcardPolicy: None

